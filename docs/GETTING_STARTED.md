# Getting Started with ConformAI

## What's Been Built ‚úÖ

Congratulations! Your ConformAI agentic RAG system is ready with:

### ‚úÖ Production-Ready Components

**Agentic RAG Service** (NEW! üî•)
- **Query Decomposition**: Automatically breaks complex queries into sub-questions
- **ReAct Agent**: Plan ‚Üí Act ‚Üí Observe loop with 5 agent tools
- **Grounding Validation**: 3-layer hallucination prevention
- **Citation Enforcement**: Every claim must be cited
- **Safety Guardrails**: Scope checking and refusal logic

**Complete Microservices**
- `api-gateway/` - FastAPI REST API
- `rag-service/` - LangGraph agentic RAG with ReAct loop ‚úÖ
- `retrieval-service/` - Vector search with Qdrant ‚úÖ
- `data-pipeline/` - EUR-Lex ingestion pipeline ‚úÖ

**Interactive Testing UI** (NEW! üé®)
- `app_demo.py` - Streamlit app for testing agent behavior
- Real-time visualization of agent reasoning
- Query history and performance metrics

**Data Pipeline**
- EUR-Lex API integration
- Legal document parser (XML/PDF/HTML)
- Legal-aware chunking
- OpenAI embeddings generation
- Qdrant vector indexing
- Airflow orchestration

### ‚úÖ Dependencies Installed
All 259+ packages installed via `uv`, including:
- LangChain ecosystem (LangChain, LangGraph, LangSmith)
- Vector database (Qdrant client)
- ML libraries (Sentence Transformers, Transformers, PyTorch)
- Airflow with providers
- FastAPI with async support
- Database tools (SQLAlchemy, PostgreSQL, Redis)

### ‚úÖ Configuration Files
- `pyproject.toml` - Complete dependency manifest
- `docker-compose.yml` - 8 containerized services
- `Makefile` - Development commands
- `.env` - Environment configuration (needs your API keys)
- `README.md` - Full documentation

---

## üöÄ Quick Start (Full System in 5 Minutes)

### Option 1: Test with Demo UI (Fastest - No Setup Required)

Perfect for testing the agentic RAG UI with sample data:

```bash
# 1. Install Streamlit
uv pip install streamlit

# 2. Run demo app (uses mock data)
streamlit run app_demo.py
```

‚úÖ **App opens at http://localhost:8501**

Test queries:
- Simple: "What is a high-risk AI system?"
- Medium: "What are the documentation requirements for high-risk AI systems?"
- Complex: "Compare documentation requirements for recruitment AI vs healthcare AI"

**See**: Query decomposition, ReAct agent reasoning, citations, performance metrics

---

### Option 2: Full End-to-End System (With Real Data)

For complete testing with document ingestion, vector search, and RAG:

#### Step 1: Configure Environment

```bash
# Edit .env file with your API keys
nano .env
```

**Required:**
```bash
OPENAI_API_KEY=your_openai_key_here  # For embeddings + LLM
```

**Optional:**
```bash
ANTHROPIC_API_KEY=your_anthropic_key  # For Claude models
OPIK_API_KEY=your_opik_key           # For LLM tracing
```

#### Step 2: Start Infrastructure

```bash
# Start Qdrant, PostgreSQL, Redis, MinIO
docker-compose up -d qdrant postgres redis minio

# Wait 30 seconds for services to start
sleep 30

# Verify services are healthy
docker-compose ps
```

You should see:
```
qdrant     running   6333/tcp
postgres   running   5432/tcp
redis      running   6379/tcp
minio      running   9000-9001/tcp
```

#### Step 3: Initialize Databases

```bash
# Initialize Qdrant collection
python scripts/init_qdrant.py

# Verify collection created
curl http://localhost:6333/collections
```

#### Step 4: Run Data Pipeline (Ingest Documents)

**Option A: Run Airflow DAGs**

```bash
# Start Airflow services
docker-compose up -d airflow-webserver airflow-scheduler airflow-worker

# Initialize Airflow (first time only)
docker-compose exec airflow-webserver airflow db init

# Create admin user (first time only)
docker-compose exec airflow-webserver \
  airflow users create \
  --username admin \
  --password admin \
  --firstname Admin \
  --lastname User \
  --role Admin \
  --email admin@example.com

# Access Airflow UI
open http://localhost:8080  # Login: admin/admin

# Trigger EUR-Lex ingestion DAG
docker-compose exec airflow-scheduler \
  airflow dags trigger eurlex_daily_ingestion

# Trigger document processing DAG
docker-compose exec airflow-scheduler \
  airflow dags trigger document_processing
```

**Option B: Run Pipeline Directly (Faster)**

```bash
# Run ingestion script
python services/data-pipeline/src/scripts/ingest_sample_docs.py

# This will:
# 1. Fetch sample EU AI Act documents
# 2. Parse and chunk them
# 3. Generate embeddings
# 4. Index to Qdrant
```

#### Step 5: Start Retrieval Service

```bash
# Terminal 1: Run retrieval service
cd services/retrieval-service
python src/api/main.py
```

‚úÖ **Retrieval service running on http://localhost:8002**

Test it:
```bash
curl -X POST http://localhost:8002/api/v1/retrieve \
  -H "Content-Type: application/json" \
  -d '{"query": "high-risk AI obligations", "top_k": 5}'
```

#### Step 6: Test RAG Agent with Streamlit UI

```bash
# Terminal 2: Run Streamlit app
streamlit run app.py
```

‚úÖ **Agent testing UI at http://localhost:8501**

**Note:** If you get import errors, use the demo version:
```bash
streamlit run app_demo.py
```

#### Step 7: Query the System

In the Streamlit UI:

1. **Select complexity**: Try "Simple", "Medium", or "Complex"
2. **Enter query** or use samples
3. **Click "Run Query"**
4. **Watch the agent**:
   - Query analysis and decomposition
   - ReAct loop iterations
   - Retrieval operations
   - Answer synthesis
   - Citations and grounding validation

**Sample Queries:**

```
üîπ Simple (1-2 iterations):
"What is a high-risk AI system?"

üî∏ Medium (3-4 iterations):
"What are the documentation requirements for high-risk AI systems?"

üî∂ Complex (5+ iterations):
"Compare the obligations for recruitment AI versus healthcare AI systems, and explain the key differences in their documentation requirements."
```

---

## üìä What to Expect

### Query Processing Flow

```
User Query
    ‚Üì
[Query Analysis]
  ‚Üí Intent: compliance_question
  ‚Üí Complexity: complex
  ‚Üí Domain: recruitment, healthcare
    ‚Üì
[Query Decomposition]
  ‚Üí Sub-Q1: "What documentation for recruitment AI?"
  ‚Üí Sub-Q2: "What documentation for healthcare AI?"
  ‚Üí Sub-Q3: "What are the key differences?"
    ‚Üì
[ReAct Agent Loop - Iteration 1]
  PLAN: "Retrieve recruitment AI documentation"
  ACT: retrieve_legal_chunks(query="recruitment AI docs")
  OBSERVE: Retrieved 8 chunks
    ‚Üì
[ReAct Agent Loop - Iteration 2]
  PLAN: "Answer recruitment sub-question"
  ACT: answer_sub_question(...)
  OBSERVE: Generated answer with 4 citations
    ‚Üì
[... More iterations ...]
    ‚Üì
[Synthesis]
  ‚Üí Combine all sub-answers
  ‚Üí Ensure coherence
  ‚Üí Maintain all citations
    ‚Üì
[Grounding Validation]
  ‚úì Citation completeness
  ‚úì Citation validity
  ‚úì Hallucination detection
    ‚Üì
[Final Answer]
  ‚Üí Comprehensive response
  ‚Üí 10+ citations
  ‚Üí Legal disclaimer
  ‚Üí Confidence: 0.89
```

### Performance Targets

- **Simple queries**: ~1-2 seconds (1-2 iterations)
- **Medium queries**: ~2-3 seconds (3-4 iterations)
- **Complex queries**: ~4-6 seconds (5-7 iterations)

---

## üéØ Access Services

| Service | URL | Purpose | Login |
|---------|-----|---------|-------|
| **Streamlit UI** | http://localhost:8501 | Agent testing interface | - |
| **Retrieval API** | http://localhost:8002 | Vector search service | - |
| **RAG API** | http://localhost:8001 | RAG orchestration | - |
| **Airflow UI** | http://localhost:8080 | Data pipeline monitoring | admin/admin |
| **Qdrant Dashboard** | http://localhost:6333/dashboard | Vector DB admin | - |
| **MinIO Console** | http://localhost:9001 | Object storage | minioadmin/minioadmin |

---

## üîß Development Workflow

### Testing the Agent

**Interactive UI (Recommended):**
```bash
streamlit run app_demo.py
```

**Command Line:**
```bash
python test_rag.py
```

**API Testing:**
```bash
# Test retrieval service
curl -X POST http://localhost:8002/api/v1/retrieve \
  -H "Content-Type: application/json" \
  -d '{"query": "high-risk AI obligations", "top_k": 10}'

# Test RAG service
curl -X POST http://localhost:8001/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{"query": "What are the obligations for high-risk AI systems?", "max_iterations": 5}'
```

### Managing Data Pipeline

```bash
# View Airflow UI
open http://localhost:8080

# Trigger ingestion manually
docker-compose exec airflow-scheduler \
  airflow dags trigger eurlex_daily_ingestion

# Check ingestion status
docker-compose logs airflow-scheduler -f

# Verify data in Qdrant
curl http://localhost:6333/collections/eu_legal_documents_development
```

### Code Quality

```bash
# Format code
make format

# Run linters
make lint

# Run tests
make test
```

---

## ‚ö° Quick Commands Reference

### Testing & Demo
```bash
# Fastest way to test agent UI (no setup)
streamlit run app_demo.py

# Test with command line
python test_rag.py

# Run full app (requires services)
streamlit run app.py
```

### Services
```bash
# Start infrastructure only
docker-compose up -d qdrant postgres redis minio

# Start all services
docker-compose up -d

# Start specific services
docker-compose up -d airflow-webserver airflow-scheduler

# Run retrieval service locally
cd services/retrieval-service && python src/api/main.py

# Run RAG service locally
cd services/rag-service && python src/api/main.py

# Stop all services
docker-compose down
```

### Data Pipeline
```bash
# Trigger EUR-Lex ingestion
docker-compose exec airflow-scheduler \
  airflow dags trigger eurlex_daily_ingestion

# Trigger document processing
docker-compose exec airflow-scheduler \
  airflow dags trigger document_processing

# View Airflow logs
docker-compose logs airflow-scheduler -f

# Check Qdrant collections
curl http://localhost:6333/collections
```

### Development
```bash
# Install dependencies
make install
uv pip install -e .

# Format code
make format

# Run linters
make lint

# Run tests
make test

# Clean build artifacts
make clean
```

### Database & Infrastructure
```bash
# Initialize Qdrant collection
python scripts/init_qdrant.py

# Check Qdrant health
curl http://localhost:6333/

# View Qdrant dashboard
open http://localhost:6333/dashboard

# Check all services status
docker-compose ps
```

### Troubleshooting
```bash
# View service logs
docker-compose logs <service-name>
docker-compose logs qdrant
docker-compose logs airflow-scheduler

# Restart specific service
docker-compose restart qdrant

# Rebuild and restart
docker-compose up -d --build <service-name>

# Check service health
curl http://localhost:6333/  # Qdrant
curl http://localhost:8002/health  # Retrieval service
curl http://localhost:8001/health  # RAG service
```

---

## Project Files Overview

| File/Directory | Purpose |
|----------------|---------|
| `shared/` | Common code shared across all services |
| `shared/config/settings.py` | Centralized configuration management |
| `shared/models/legal_document.py` | Pydantic models for legal documents |
| `services/api-gateway/src/main.py` | FastAPI application entry point |
| `airflow/dags/eurlex_ingestion_dag.py` | EUR-Lex data ingestion pipeline |
| `docker-compose.yml` | All services orchestration |
| `Makefile` | Development commands |
| `.env` | Environment variables (add your API keys here) |

---

## Architecture Highlights

### Microservices
- **API Gateway** (Port 8000) - Public REST API
- **RAG Service** (Port 8001) - LangGraph orchestrator
- **Retrieval Service** (Port 8002) - LangChain retrieval

### Infrastructure
- **Qdrant** (Port 6333) - Vector database for embeddings
- **PostgreSQL** (Port 5432) - Metadata & versions
- **Redis** (Port 6379) - Cache & Celery broker
- **Airflow** (Port 8080) - Data pipeline orchestration
- **MinIO** (Ports 9000/9001) - S3-compatible object storage

### Data Flow
```
EUR-Lex API
    ‚Üì
Airflow DAG (ingest)
    ‚Üì
Document Parser
    ‚Üì
Legal Chunker
    ‚Üì
Embeddings (BGE)
    ‚Üì
Qdrant (vector store)
    ‚Üì
LangGraph RAG
    ‚Üì
FastAPI Response
```

---

## Troubleshooting

### Services won't start
```bash
# Check Docker status
docker-compose ps

# View logs
docker-compose logs qdrant
docker-compose logs postgres

# Restart specific service
docker-compose restart qdrant
```

### Airflow shows "No module named 'shared'"
```bash
# Rebuild Airflow with shared modules
docker-compose build airflow-webserver
docker-compose up -d airflow-webserver airflow-scheduler
```

### Can't connect to Qdrant
```bash
# Check Qdrant health
curl http://localhost:6333/

# Restart Qdrant
docker-compose restart qdrant
```

---

## Resources

- **Technical Plan**: [TECHNICAL_IMPLEMENTATION_PLAN.md](TECHNICAL_IMPLEMENTATION_PLAN.md)
- **Project Vision**: [claude.md](claude.md)
- **API Docs**: http://localhost:8000/docs (when running)
- **LangChain Docs**: https://python.langchain.com/
- **LangGraph Docs**: https://langchain-ai.github.io/langgraph/
- **Qdrant Docs**: https://qdrant.tech/documentation/
- **Airflow Docs**: https://airflow.apache.org/docs/

---

## Support

For questions or issues:
1. Check [TECHNICAL_IMPLEMENTATION_PLAN.md](TECHNICAL_IMPLEMENTATION_PLAN.md)
2. Review service logs: `docker-compose logs <service-name>`
3. Verify .env configuration
4. Check service health: `docker-compose ps`

---

## ‚úÖ Implementation Status

### Fully Implemented & Working

‚úÖ **Agentic RAG Service**
- Query decomposition (simple/medium/complex)
- ReAct agent with 5 tools (retrieve, answer, synthesize, validate, search)
- Plan ‚Üí Act ‚Üí Observe loop (max 5 iterations)
- Grounding validation (3-layer hallucination prevention)
- Citation enforcement
- Safety guardrails

‚úÖ **Retrieval Service**
- Qdrant vector search
- OpenAI embeddings
- Metadata filtering
- Batch retrieval
- Health checks

‚úÖ **Data Pipeline**
- EUR-Lex API client
- Legal document parser (XML/PDF/HTML)
- Legal-aware chunking (article + paragraph level)
- Embedding generation (OpenAI text-embedding-3-large)
- Qdrant indexing
- Airflow DAGs (ingestion + processing)

‚úÖ **Testing Infrastructure**
- Streamlit demo UI (`app_demo.py`) - working with mock data
- Command-line test script (`test_rag.py`)
- API endpoints (retrieval + RAG services)

### Needs Configuration

‚öôÔ∏è **Full End-to-End Flow**
- Requires: API keys in `.env`
- Requires: Docker services running
- Requires: Documents ingested into Qdrant
- Fix: Module imports (`rag-service` ‚Üí `rag_service`)

‚öôÔ∏è **Production Deployment**
- Kubernetes manifests exist but need testing
- Monitoring dashboards need setup
- Secrets management via K8s secrets

### Optional Enhancements

üí° **Nice to Have (Not Required)**
- Hybrid search (semantic + BM25)
- Cross-encoder reranking
- Streaming responses
- Query caching
- Cost tracking
- A/B testing framework

---

## üéâ You're Ready!

**What you can do RIGHT NOW:**

1. **Test the agent UI** (fastest, no setup):
   ```bash
   streamlit run app_demo.py
   ```

2. **Test full system** (with setup):
   ```bash
   # Start infrastructure
   docker-compose up -d qdrant postgres redis

   # Run retrieval service
   cd services/retrieval-service && python src/api/main.py &

   # Run Streamlit
   streamlit run app_demo.py
   ```

3. **Review the code**:
   - RAG service: `services/rag-service/src/graph/`
   - Retrieval service: `services/retrieval-service/src/`
   - Data pipeline: `services/data-pipeline/src/`

---

**Next recommended action:** **Test the demo UI** with `streamlit run app_demo.py` üöÄ

For questions, check:
- [RAG_IMPLEMENTATION_PLAN.md](RAG_IMPLEMENTATION_PLAN.md) - Detailed RAG architecture
- [RUNNING_THE_APP.md](RUNNING_THE_APP.md) - App usage guide
- [TECHNICAL_IMPLEMENTATION_PLAN.md](TECHNICAL_IMPLEMENTATION_PLAN.md) - Full system design
